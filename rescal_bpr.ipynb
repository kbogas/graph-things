{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy\n",
    "# with open('./data/drug_drug_500.np', 'r') as f:\n",
    "#     dd = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "#import numpy as np\n",
    "\n",
    "def load_csvfile(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def convert_dataframe_to_sparse(matrix):\n",
    "    return sp.csr_matrix(matrix)\n",
    "\n",
    "def convert_data_to_multiarray(data):\n",
    "    \"\"\"\n",
    "    Convert data to a multiway array by stacking matrix slices\n",
    "    (also sparse version)\n",
    "    \"\"\"\n",
    "    adj_matrices = []\n",
    "    adj_sp_matrices = []\n",
    "    unique_seffects = data.iloc[:, 2].unique()\n",
    "    # build a huge zeros matrix for all nodes\n",
    "    columns = (data.iloc[:, i] for i in range(2))\n",
    "    df = pd.crosstab(*columns)\n",
    "    #df = pd.crosstab(data.a, data.b)\n",
    "    idx = df.columns.union(df.index)\n",
    "    adj_matrix_all = df.reindex(index=idx, columns=idx, fill_value=0)\n",
    "\n",
    "    # for each disease get all interaction rows\n",
    "    # and construct a DxDx#unique_seffects\n",
    "    #print len(unique_seffects.tolist())\n",
    "\n",
    "    for se in unique_seffects.tolist():\n",
    "        adj_matrix_all[adj_matrix_all>0] = 0\n",
    "        subdata = data.loc[data.iloc[:, 2] == se]\n",
    "        #columns = (subdata.iloc[:, i] for i in range(3))\n",
    "        for c in subdata.values:\n",
    "            row = c[0]\n",
    "            column = c[1]\n",
    "            adj_matrix_all.at[row, column] = 1\n",
    "        adj_matrices.append(adj_matrix_all.values)\n",
    "        sparse_matrix = convert_dataframe_to_sparse(adj_matrix_all)\n",
    "        adj_sp_matrices.append(sparse_matrix)\n",
    "    #multiarray = np.dstack(adj_matrices)\n",
    "\n",
    "    return adj_sp_matrices\n",
    "\n",
    "datafile = load_csvfile(\"./data/bio-decagon-combo.csv\")\n",
    "multiarray = convert_data_to_multiarray(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import tqdm\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def bpr(X, rank=10, alpha=0.05, lambdaA=0.0001, lambdaR=0.00001, max_iter=500, init={'key':'normal', 'mean':0,'std':0.01}):\n",
    "    \"\"\"\n",
    "    X: list of matices, mandatory\n",
    "    rank:\n",
    "    lambdaA : float, optional\n",
    "        Regularization parameter for A factor matrix. 0 by default\n",
    "    lmbdaR : float, optional\n",
    "        Regularization parameter for R_k factor matrices. 0 by default\n",
    "    lmbdaV : float, optional\n",
    "    init : string, optional\n",
    "        'normal' initializes the factor matrices randomly.\n",
    "    compute_fit : boolean, optional\n",
    "        If true, compute the fit of the factorization compared to X.\n",
    "        For large sparse tensors this should be turned of. None by default.\n",
    "    \"\"\"\n",
    "    k = len(X)\n",
    "    dim, _ = X[0].shape\n",
    "    A, R = initialize_matrices(X, rank, dim, k, init)\n",
    "    for iter_ in tqdm.tqdm(xrange(max_iter)):\n",
    "        #P = reconstruct(A, R)\n",
    "        i, j, r, r_neg = draw_samples(X)\n",
    "        #print P.sum()\n",
    "        a_j_R_pos = np.dot(R[:,:,r], A[j,:].T)\n",
    "        a_j_R_neg = np.dot(R[:,:,r_neg], A[j,:].T)\n",
    "        y_hat = np.dot(A[i,:], a_j_R_pos) - np.dot(A[i,:], a_j_R_neg)\n",
    "        #y_hat = predict(A,R,i,j,r) - predict(A,R,i,j,r_neg)\n",
    "        delta = 1-sigmoid(y_hat)\n",
    "        #print delta\n",
    "        delta_alpha_i = np.dot(A[i,:], R[:,:,r])  - np.dot(A[i,:], R[:,:,r_neg])\n",
    "        delta_alpha_j = a_j_R_pos - a_j_R_neg\n",
    "        delta_rel = np.outer(A[i,:], A[j,:])\n",
    "        A[i,:] = A[i,:] + alpha*(delta*delta_alpha_i - lambdaA*A[i,:])\n",
    "        A[j,:] = A[j,:] + alpha*(delta*delta_alpha_j - lambdaA*A[j,:])\n",
    "        R[:,:,r] = R[:,:,r] + alpha*(delta*delta_rel - lambdaR*R[:,:,r])\n",
    "        R[:,:,r_neg] = R[:,:,r_neg] + alpha*(-delta*delta_rel - lambdaR*R[:,:,r_neg])\n",
    "    return A, R\n",
    "        \n",
    "def reconstruct(A, R):\n",
    "    P = np.zeros((A.shape[0], A.shape[0], R.shape[2]))\n",
    "    for k in range(len(R)):\n",
    "        P[:, :, k] = np.dot(A, np.dot(R[:,:,k], A.T))\n",
    "    return P\n",
    "    \n",
    "def predict(A, R, i, j, r):\n",
    "    #print A[i,:].shape, R[:,:,r].shape, A[j,:].T.shape\n",
    "    return  np.dot(A[i,:], np.dot(R[:,:,r], A[j,:].T))\n",
    "\t\n",
    "    \n",
    "def draw_negative_sample(r, N):\n",
    "    r_dot = np.random.randint(N) # sample random index\n",
    "    while r_dot==r:\n",
    "        r_dot = np.random.randint(N) # repeat while the same index is sampled\n",
    "    return r_dot\n",
    "\n",
    "def sigmoid(x):\n",
    "    if x > 20:\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        sigm = 1.0 / (1.0 + np.exp(-x))   \n",
    "        if sigm > 0.5:\n",
    "            #print 'ole'\n",
    "            return sigm\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "def initialize_matrices(X, rank, dim, k, init):\n",
    "    \"\"\"\n",
    "    Initialize the A, R matrices.\n",
    "    \"\"\"\n",
    "    if init['key'] == 'normal':\n",
    "        A = np.random.uniform(init['mean'], init['std'], size=(dim, rank))\n",
    "        R = np.random.uniform(init['mean'], init['std'], size=(rank, rank, k))\n",
    "    elif init['key'] == 'nvecs':\n",
    "        S = sparse.csr_matrix((dim, dim))\n",
    "        for i in range(k):\n",
    "            S = S + X[i]\n",
    "            S = S + X[i].T\n",
    "        _, A = sparse.linalg.eigsh(sparse.csr_matrix(S, shape=(dim, dim)), rank)\n",
    "        A = array(A, dtype=dtype)\n",
    "    else:\n",
    "        print('Initialization method not found!')\n",
    "        print(init)\n",
    "        raise KeyError\n",
    "    return A, R\n",
    "\n",
    "def draw_samples(X, N=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: list of matices, mandatory\n",
    "    Output:\n",
    "        pos: tuple, int\n",
    "        indices of i,j,r positive triples\n",
    "        neg: tuple, int\n",
    "        indices of i,j,r neg triples\n",
    "    \"\"\"\n",
    "    if N == 1:\n",
    "        r = np.random.randint(len(X))\n",
    "        nnz = np.transpose(np.nonzero(X[r]))\n",
    "        i, j = nnz[np.random.choice(nnz.shape[0])]\n",
    "        neg = np.random.choice([k for k in xrange(len(X)) if X[k][i,j]==0])\n",
    "    else:\n",
    "        i = j = r = neg = []\n",
    "        for xx in xrange(N):\n",
    "            r.append(np.random.randint(len(X)))\n",
    "            nnz = np.transpose(np.nonzero(X[r]))\n",
    "            ii, jj = nnz[np.random.choice(nnz.shape[0])]\n",
    "            i.append(ii)\n",
    "            j.append(jj)\n",
    "            neg.append(np.random.choice([k for k in xrange(len(X)) if X[k][i,j]==0]))\n",
    "    return i, j, r, neg\n",
    "A, R = bpr(multiarray, 10, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(multiarray_sparse, sample=None):\n",
    "    marrays = []\n",
    "    if sample:\n",
    "        sorted_m = sorted(multiarray_sparse, key=sp.csr_matrix.getnnz)\n",
    "        for m in sorted_m[-sample:]:\n",
    "            marrays.append(m.toarray())\n",
    "        T = np.array(marrays).T\n",
    "    else:\n",
    "        for m in multiarray_sparse:\n",
    "            marrays.append(m.toarray())\n",
    "        T = np.array(marrays).T\n",
    "    return T\n",
    "\n",
    "def normalize_predictions(P, e, k):\n",
    "    print(P.shape)\n",
    "    for a in range(e):\n",
    "        for b in range(e):\n",
    "            nrm = np.linalg.norm(P[a, b, :k])\n",
    "            if nrm != 0:\n",
    "                # round values for faster computation of AUC-PR\n",
    "                P[a, b, :k] = np.round_(P[a, b, :k] / nrm, decimals=3)\n",
    "    return P\n",
    "\n",
    "data = to_tensor(multiarray, sample=500)\n",
    "e, k = data.shape[0], data.shape[2]\n",
    "print(\"Dataset size: \", data.shape)\n",
    "SZ = e * e * k\n",
    "# T for rescal\n",
    "T = [sp.lil_matrix(data[:, :, i]) for i in range(k)]\n",
    "\n",
    "A, R = bpr(T, 10, max_iter=10000)\n",
    "n = A.shape[0]\n",
    "P = np.zeros((n, n, R.shape[2]))\n",
    "for k_i in range(R.shape[2]):\n",
    "    P[:, :, k_i] = np.dot(A, np.dot(R[:,:,k_i], A.T))\n",
    "P = normalize_predictions(P, e, k)\n",
    "print(\"Error: \", np.linalg.norm(data-P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = A.shape[0]\n",
    "P = np.zeros((n, n, R.shape[2]))\n",
    "for k_i in range(R.shape[2]):\n",
    "    P[:, :, k_i] = np.dot(A, np.dot(R[:,:,k_i], A.T))\n",
    "P = normalize_predictions(P, e, k)\n",
    "print(\"Error: \", np.linalg.norm(data-P))\n",
    "print P[:,:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial loss:', 2.772588722239781)\n",
      "('Trained loss:', 1.067270675787016)\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (np.tanh(x / 2.) + 1)\n",
    "\n",
    "def logistic_predictions(weights, inputs):\n",
    "    # Outputs probability of a label being true according to logistic model.\n",
    "    return sigmoid(np.dot(inputs, weights))\n",
    "\n",
    "def training_loss(weights):\n",
    "    # Training loss is the negative log-likelihood of the training labels.\n",
    "    preds = logistic_predictions(weights, inputs)\n",
    "    label_probabilities = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -np.sum(np.log(label_probabilities))\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = np.array([[0.52, 1.12,  0.77],\n",
    "                   [0.88, -1.08, 0.15],\n",
    "                   [0.52, 0.06, -1.30],\n",
    "                   [0.74, -2.49, 1.39]])\n",
    "targets = np.array([True, True, False, True])\n",
    "\n",
    "# Define a function that returns gradients of training loss using Autograd.\n",
    "training_gradient_fun = grad(training_loss)\n",
    "\n",
    "# Optimize weights using gradient descent.\n",
    "weights = np.array([0.0, 0.0, 0.0])\n",
    "print(\"Initial loss:\", training_loss(weights))\n",
    "for i in range(100):\n",
    "    weights -= training_gradient_fun(weights) * 0.01\n",
    "\n",
    "print(\"Trained loss:\", training_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_samples(X, N=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: list of matices, mandatory\n",
    "    Output:\n",
    "        pos: tuple, int\n",
    "        indices of i,j,r positive triples\n",
    "        neg: tuple, int\n",
    "        indices of i,j,r neg triples\n",
    "    \"\"\"\n",
    "    if N == 1:\n",
    "        r = np.random.randint(len(X))\n",
    "        nnz = np.transpose(np.nonzero(X[r]))\n",
    "        i, j = nnz[np.random.choice(nnz.shape[0])]\n",
    "        neg = np.random.choice([k for k in xrange(len(X)) if X[k][i,j]==0])\n",
    "    else:\n",
    "        i = j = r = neg = []\n",
    "        for xx in xrange(N):\n",
    "            r.append(np.random.randint(len(X)))\n",
    "            nnz = np.transpose(np.nonzero(X[r[-1]]))\n",
    "            ii, jj = nnz[np.random.choice(nnz.shape[0])]\n",
    "            i.append(ii)\n",
    "            j.append(jj)\n",
    "            neg.append(np.random.choice([k for k in xrange(len(X)) if X[k][i[-1],j[-1]]==0]))\n",
    "    return i, j, r, neg\n",
    "N = 100\n",
    "i, j, r, r_neg = draw_samples(multiarray, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nnz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4e8a2a2be5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nnz' is not defined"
     ]
    }
   ],
   "source": [
    "nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-520723d6f961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_get_single_element\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index out of bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mmajor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataset size: ', (645, 645, 500))\n"
     ]
    }
   ],
   "source": [
    "def to_tensor(multiarray_sparse, sample=None):\n",
    "    marrays = []\n",
    "    if sample:\n",
    "        sorted_m = sorted(multiarray_sparse, key=sp.csr_matrix.getnnz)\n",
    "        for m in sorted_m[-sample:]:\n",
    "            marrays.append(m.toarray())\n",
    "        T = np.array(marrays).T\n",
    "    else:\n",
    "        for m in multiarray_sparse:\n",
    "            marrays.append(m.toarray())\n",
    "        T = np.array(marrays).T\n",
    "    return T\n",
    "\n",
    "\n",
    "data = to_tensor(multiarray, sample=500)\n",
    "e, k = data.shape[0], data.shape[2]\n",
    "print(\"Dataset size: \", data.shape)\n",
    "SZ = e * e * k\n",
    "# T for rescal\n",
    "del T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-94250e8985a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not tuple"
     ]
    }
   ],
   "source": [
    "T[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial loss:', -1.5487267262981368e-05)\n",
      "Loss at 0 : -0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e06347f9e98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBPR_LOSS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrad_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrad_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at %d : %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBPR_LOSS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/autograd/wrap_util.pyc\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/autograd/differential_operators.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/autograd/core.pyc\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/autograd/tracer.pyc\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/autograd/wrap_util.pyc\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-e06347f9e98c>\u001b[0m in \u001b[0;36mBPR_LOSS\u001b[0;34m(A, R, X, batch_size, lambdaA, lambdaR)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#a_j_R_pos = np.dot(R[:,:,r], A[j,:].T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#a_j_R_neg = np.dot(R[:,:,r_neg], A[j,:].T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-228c928b53ca>\u001b[0m in \u001b[0;36mdraw_samples\u001b[0;34m(X, N)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# First attempt to use original row optimized methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# [1, ?]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;31m# [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36misintlike\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def predict(A, R, i, j, r):\n",
    "    #print A[i,:].shape, R[:,:,r].shape, A[j,:].T.shape\n",
    "    return  np.dot(A[i,:], np.dot(R[:,:,r], A[j,:].T))\n",
    "\n",
    "def BPR_LOSS(A,R,X, batch_size=100, lambdaA=0.0001, lambdaR=0.00001):\n",
    "    pairs = []\n",
    "    y_hat = 0\n",
    "    for b in xrange(batch_size):\n",
    "        i, j, r, r_neg = draw_samples(X)\n",
    "        #a_j_R_pos = np.dot(R[:,:,r], A[j,:].T)\n",
    "        #a_j_R_neg = np.dot(R[:,:,r_neg], A[j,:].T)\n",
    "        #y_hat += sigmoid(np.dot(A[i,:], a_j_R_pos) - np.dot(A[i,:], a_j_R_neg))\n",
    "        y_hat += predict(A,R,i,j,r) - predict(A,R,i,j,r_neg)\n",
    "    return -y_hat #- lambdaA*np.linalg.norm(A) -  lambdaA*np.linalg.norm(R))\n",
    "#BPR_LOSS(A,R,multiarray)\n",
    "\n",
    "rank=10\n",
    "init={'key':'normal', 'mean':0,'std':0.01}\n",
    "\n",
    "grad_a = grad(BPR_LOSS, 0)\n",
    "grad_r = grad(BPR_LOSS, 1)\n",
    "\n",
    "k = len(multiarray)\n",
    "dim, _ = multiarray[0].shape\n",
    "A, R = initialize_matrices(rank, dim, k, init)\n",
    "print(\"Initial loss:\", BPR_LOSS(A,R,multiarray))\n",
    "for i in range(100):\n",
    "    A += grad_a(A,R,multiarray) * 0.01\n",
    "    R += grad_r(A,R,multiarray) * 0.01\n",
    "    print(\"Loss at %d : %0.3f\" % (i,BPR_LOSS(A,R,multiarray)))\n",
    "\n",
    "print(\"Trained loss:\", training_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " k = len(X)\n",
    "    dim, _ = X[0].shape\n",
    "    A, R = initialize_matrices(rank, dim, k, init)\n",
    "    for iter_ in tqdm.tqdm(xrange(max_iter)):\n",
    "        #P = reconstruct(A, R)\n",
    "        i, j, r, r_neg = draw_samples(X)\n",
    "        #print P.sum()\n",
    "        a_j_R_pos = np.dot(R[:,:,r], A[j,:].T)\n",
    "        a_j_R_neg = np.dot(R[:,:,r_neg], A[j,:].T)\n",
    "        y_hat = np.dot(A[i,:], a_j_R_pos) - np.dot(A[i,:], a_j_R_neg)\n",
    "        #y_hat = predict(A,R,i,j,r) - predict(A,R,i,j,r_neg)\n",
    "        delta = 1-sigmoid(y_hat)\n",
    "        #print delta\n",
    "        delta_alpha_i = np.dot(A[i,:], R[:,:,r])  - np.dot(A[i,:], R[:,:,r_neg])\n",
    "        delta_alpha_j = a_j_R_pos - a_j_R_neg\n",
    "        delta_rel = np.outer(A[i,:], A[j,:])\n",
    "        A[i,:] = A[i,:] + alpha*(delta*delta_alpha_i - lambdaA*A[i,:])\n",
    "        A[j,:] = A[j,:] + alpha*(delta*delta_alpha_j - lambdaA*A[j,:])\n",
    "        R[:,:,r] = R[:,:,r] + alpha*(delta*delta_rel - lambdaR*R[:,:,r])\n",
    "        R[:,:,r_neg] = R[:,:,r_neg] + alpha*(-delta*delta_rel - lambdaR*R[:,:,r_neg])\n",
    "    return A, R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
